{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d9700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 입력 언어: 영어 (en-US)\n",
      "🔄 출력 언어: 한국어 (ko)\n",
      "==================================================\n",
      "🎯 Azure STT → 번역 → TTS 통합 시스템\n",
      "==================================================\n",
      "1. 마이크 실시간 처리 (계속 실행)\n",
      "2. 오디오 파일 처리\n",
      "0. 종료\n",
      "🎤 영어 실시간 음성 인식 시작\n",
      "말씀하시면 자동으로 번역되고 음성 출력됩니다.\n",
      "종료하려면 'q' 또는 'quit'을 입력하세요.\n",
      "--------------------------------------------------\n",
      "👋 사용자가 종료를 요청했습니다.\n",
      "🛑 음성 인식을 중지합니다...\n",
      "🛑 세션 종료: SessionEventArgs(session_id=3663f456a6fd4dedb769e9cc561cf29b)\n",
      "👋 프로그램을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from azure.ai.translation.text import TextTranslationClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from pydub import AudioSegment\n",
    "from datetime import datetime\n",
    "\n",
    "# 환경변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# Azure 설정\n",
    "speech_api_key = os.getenv(\"SPEECH_API_KEY\")\n",
    "region = os.getenv(\"SPEECH_REGION\")\n",
    "translator_api_key = os.getenv(\"TRANSLATOR_API_KEY\")\n",
    "translator_region = os.getenv(\"TRANSLATOR_REGION\")\n",
    "translator_endpoint = os.getenv(\"TRANSLATOR_ENDPOINT\")\n",
    "\n",
    "# ==================== 언어 설정 ====================\n",
    "INPUT_LANGUAGE = \"영어\"      # STT 입력 언어\n",
    "OUTPUT_LANGUAGE = \"한국어\"       # 번역 출력 + TTS 출력 언어\n",
    "\n",
    "# 언어 매핑 테이블\n",
    "LANGUAGE_MAPPING = {\n",
    "    \"한국어\": (\"ko-KR\", \"ko\", \"ko-KR-SunHiNeural\"),\n",
    "    \"영어\": (\"en-US\", \"en\", \"en-US-AvaMultilingualNeural\"),\n",
    "    \"중국어(간체)\": (\"zh-CN\", \"zh-Hans\", \"zh-CN-XiaoxiaoNeural\"),\n",
    "    \"일본어\": (\"ja-JP\", \"ja\", \"ja-JP-NanamiNeural\"),\n",
    "    \"독일어\": (\"de-DE\", \"de\", \"de-DE-KatjaNeural\"),\n",
    "    \"프랑스어\": (\"fr-FR\", \"fr\", \"fr-FR-DeniseNeural\"),\n",
    "    \"스페인어\": (\"es-ES\", \"es\", \"es-ES-ElviraNeural\"),\n",
    "    \"이탈리아어\": (\"it-IT\", \"it\", \"it-IT-IsabellaNeural\"),\n",
    "    \"러시아어\": (\"ru-RU\", \"ru\", \"ru-RU-DariyaNeural\"),\n",
    "    \"포르투갈어\": (\"pt-BR\", \"pt\", \"pt-BR-FranciscaNeural\"),\n",
    "}\n",
    "\n",
    "INPUT_STT_CODE, INPUT_TRANSLATE_CODE, INPUT_TTS_VOICE = LANGUAGE_MAPPING[INPUT_LANGUAGE]\n",
    "OUTPUT_STT_CODE, OUTPUT_TRANSLATE_CODE, OUTPUT_TTS_VOICE = LANGUAGE_MAPPING[OUTPUT_LANGUAGE]\n",
    "\n",
    "print(f\"🎤 입력 언어: {INPUT_LANGUAGE} ({INPUT_STT_CODE})\")\n",
    "print(f\"🔄 출력 언어: {OUTPUT_LANGUAGE} ({OUTPUT_TRANSLATE_CODE})\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# STT 설정\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_api_key, region=region)\n",
    "speech_config.speech_recognition_language = INPUT_STT_CODE\n",
    "\n",
    "# FFmpeg 경로 설정\n",
    "AudioSegment.converter = r\"C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "AudioSegment.ffprobe = r\"C:\\\\ffmpeg\\\\bin\\\\ffprobe.exe\"\n",
    "\n",
    "# 번역기 설정\n",
    "translator_credential = AzureKeyCredential(translator_api_key)\n",
    "translator = TextTranslationClient(\n",
    "    credential=translator_credential,\n",
    "    endpoint=translator_endpoint,\n",
    "    region=translator_region\n",
    ")\n",
    "\n",
    "# TTS 설정\n",
    "tts_config = speechsdk.SpeechConfig(subscription=speech_api_key, region=region)\n",
    "tts_config.speech_synthesis_voice_name = OUTPUT_TTS_VOICE\n",
    "\n",
    "# ==================== 번역 함수 ====================\n",
    "def translate_text(text, target_language=OUTPUT_TRANSLATE_CODE):\n",
    "    \"\"\"텍스트 번역\"\"\"\n",
    "    try:\n",
    "        response = translator.translate(\n",
    "            body=[{\"text\": text}],\n",
    "            to_language=[target_language]\n",
    "        )\n",
    "        \n",
    "        # 응답이 리스트 형태이므로 올바르게 접근\n",
    "        if isinstance(response, list) and len(response) > 0:\n",
    "            translation_result = response\n",
    "            \n",
    "            # translations도 리스트 형태\n",
    "            if hasattr(translation_result, 'translations') and len(translation_result.translations) > 0:\n",
    "                translated_text = translation_result.translations.text\n",
    "            else:\n",
    "                print(f\"❌ 번역 결과 구조 오류: {translation_result}\")\n",
    "                return {\"original_text\": text, \"translated_text\": None, \"error\": \"Invalid response structure\"}\n",
    "            \n",
    "            # 언어 감지 결과\n",
    "            detected_language = None\n",
    "            if hasattr(translation_result, 'detected_language') and translation_result.detected_language:\n",
    "                detected_language = translation_result.detected_language.language\n",
    "            \n",
    "            return {\n",
    "                \"original_text\": text,\n",
    "                \"translated_text\": translated_text,\n",
    "                \"detected_language\": detected_language\n",
    "            }\n",
    "        else:\n",
    "            print(f\"❌ 빈 응답: {response}\")\n",
    "            return {\"original_text\": text, \"translated_text\": None, \"error\": \"Empty response\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 번역 오류: {e}\")\n",
    "        print(f\"   원본 텍스트: {text}\")\n",
    "        return {\"original_text\": text, \"translated_text\": None, \"error\": str(e)}\n",
    "\n",
    "\n",
    "# ==================== TTS 함수 ====================\n",
    "def speak_text(text, output_method=\"speaker\"):\n",
    "    \"\"\"TTS 음성 출력\"\"\"\n",
    "    if not text.strip():\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if output_method == \"speaker\":\n",
    "            audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "        else:  # file\n",
    "            now = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "            filename = f\"tts_output_{now}.wav\"\n",
    "            audio_config = speechsdk.audio.AudioOutputConfig(filename=filename)\n",
    "        \n",
    "        synthesizer = speechsdk.SpeechSynthesizer(tts_config, audio_config)\n",
    "        result = synthesizer.speak_text_async(text).get()\n",
    "        \n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            if output_method == \"speaker\":\n",
    "                print(f\"🔊 [{OUTPUT_LANGUAGE}] TTS 출력 완료\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"💾 [{OUTPUT_LANGUAGE}] 파일 저장: {filename}\")\n",
    "                return filename\n",
    "        else:\n",
    "            print(f\"❌ TTS 실패: {result.cancellation_details.reason}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"❌ TTS 오류: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==================== 실시간 연속 음성 인식 (사용자 입력까지 계속 실행) ====================\n",
    "def continuous_microphone_recognition():\n",
    "    \"\"\"사용자가 종료 명령을 입력하기 전까지 계속 실행되는 음성 인식\"\"\"\n",
    "    \n",
    "    print(f\"🎤 {INPUT_LANGUAGE} 실시간 음성 인식 시작\")\n",
    "    print(\"말씀하시면 자동으로 번역되고 음성 출력됩니다.\")\n",
    "    print(\"종료하려면 'q' 또는 'quit'을 입력하세요.\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 마이크 입력 설정\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config, audio_config)\n",
    "    \n",
    "    # 인식 완료 플래그\n",
    "    done = False\n",
    "    \n",
    "    def recognized_handler(evt):\n",
    "        \"\"\"음성 인식 완료 시 자동으로 번역 및 TTS 실행\"\"\"\n",
    "        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech and evt.result.text.strip():\n",
    "            original_text = evt.result.text.strip()\n",
    "            print(f\"\\n✅ 인식: {original_text}\")\n",
    "            \n",
    "            # 자동 번역\n",
    "            result = translate_text(original_text)\n",
    "            if result.get(\"translated_text\"):\n",
    "                translated = result[\"translated_text\"]\n",
    "                detected = result.get(\"detected_language\", \"unknown\")\n",
    "                print(f\"🔄 번역: {translated} (감지언어: {detected})\")\n",
    "                \n",
    "                # 자동 TTS\n",
    "                speak_text(translated, \"speaker\")\n",
    "            else:\n",
    "                print(\"❌ 번역 실패\")\n",
    "            \n",
    "            print(\"-\" * 30)\n",
    "    \n",
    "    def recognizing_handler(evt):\n",
    "        \"\"\"실시간 인식 중 (부분 결과)\"\"\"\n",
    "        if evt.result.reason == speechsdk.ResultReason.RecognizingSpeech and evt.result.text.strip():\n",
    "            print(f\"🎤 인식중: {evt.result.text.strip()}\", end='\\r')\n",
    "    \n",
    "    def stop_handler(evt):\n",
    "        \"\"\"세션 종료 핸들러\"\"\"\n",
    "        nonlocal done\n",
    "        print(f\"🛑 세션 종료: {evt}\")\n",
    "        done = True\n",
    "    \n",
    "    def canceled_handler(evt):\n",
    "        \"\"\"취소 핸들러\"\"\"\n",
    "        nonlocal done\n",
    "        print(f\"❌ 인식 취소: {evt}\")\n",
    "        done = True\n",
    "    \n",
    "    # 이벤트 핸들러 연결\n",
    "    speech_recognizer.recognized.connect(recognized_handler)\n",
    "    speech_recognizer.recognizing.connect(recognizing_handler)\n",
    "    speech_recognizer.session_stopped.connect(stop_handler)\n",
    "    speech_recognizer.canceled.connect(canceled_handler)\n",
    "    \n",
    "    # 연속 인식 시작\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    \n",
    "    # 사용자 입력을 별도 스레드에서 처리\n",
    "    def wait_for_user_input():\n",
    "        nonlocal done\n",
    "        while not done:\n",
    "            try:\n",
    "                user_input = input().strip().lower()\n",
    "                if user_input in ['q', 'quit', 'exit', '종료']:\n",
    "                    print(\"👋 사용자가 종료를 요청했습니다.\")\n",
    "                    done = True\n",
    "                    break\n",
    "            except (EOFError, KeyboardInterrupt):\n",
    "                print(\"\\n👋 키보드 인터럽트로 종료합니다.\")\n",
    "                done = True\n",
    "                break\n",
    "    \n",
    "    # 입력 대기 스레드 시작\n",
    "    input_thread = threading.Thread(target=wait_for_user_input, daemon=True)\n",
    "    input_thread.start()\n",
    "    \n",
    "    # 메인 루프 (done이 True가 될 때까지 계속 실행)\n",
    "    try:\n",
    "        while not done:\n",
    "            time.sleep(0.5)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n👋 키보드 인터럽트로 종료합니다.\")\n",
    "        done = True\n",
    "    finally:\n",
    "        # 인식 중지\n",
    "        print(\"🛑 음성 인식을 중지합니다...\")\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "\n",
    "# ==================== 디버깅 ========================\n",
    "def translate_text_debug(text, target_language=OUTPUT_TRANSLATE_CODE):\n",
    "    \"\"\"디버깅을 위한 번역 함수\"\"\"\n",
    "    try:\n",
    "        print(f\"🔍 번역 요청: '{text}' -> {target_language}\")\n",
    "        \n",
    "        response = translator.translate(\n",
    "            body=[{\"text\": text}],\n",
    "            to_language=[target_language]\n",
    "        )\n",
    "        \n",
    "        print(f\"🔍 응답 타입: {type(response)}\")\n",
    "        print(f\"🔍 응답 내용: {response}\")\n",
    "        \n",
    "        if isinstance(response, list) and len(response) > 0:\n",
    "            translation_result = response\n",
    "            print(f\"🔍 첫 번째 결과: {type(translation_result)}\")\n",
    "            print(f\"🔍 결과 속성: {dir(translation_result)}\")\n",
    "            \n",
    "            if hasattr(translation_result, 'translations'):\n",
    "                print(f\"🔍 translations 타입: {type(translation_result.translations)}\")\n",
    "                print(f\"🔍 translations 내용: {translation_result.translations}\")\n",
    "                \n",
    "                if len(translation_result.translations) > 0:\n",
    "                    translated_text = translation_result.translations.text\n",
    "                    print(f\"✅ 번역 성공: {translated_text}\")\n",
    "                    return translated_text\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 번역 오류 상세: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# ==================== 메인 실행부 ====================\n",
    "def main():\n",
    "    print(\"🎯 Azure STT → 번역 → TTS 통합 시스템\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"1. 마이크 실시간 처리 (계속 실행)\")\n",
    "    print(\"2. 오디오 파일 처리\")\n",
    "    print(\"0. 종료\")\n",
    "    \n",
    "    while True:\n",
    "        choice = input(\"\\n선택하세요 > \").strip()\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            # 실시간 연속 인식 (사용자가 종료하기 전까지 계속)\n",
    "            continuous_microphone_recognition()\n",
    "            \n",
    "        elif choice == \"2\":\n",
    "            # 파일 입력 처리  \n",
    "            file_path = input(\"오디오 파일 경로 입력 > \").strip()\n",
    "            \n",
    "            if not os.path.exists(file_path):\n",
    "                print(\"❌ 파일이 존재하지 않습니다.\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"📁 파일 처리 중: {file_path}\")\n",
    "            \n",
    "            # 파일 형식 확인 및 변환\n",
    "            direct_process_exts = [\".wav\", \".pcm\", \".wave\", \".flac\"]\n",
    "            file_ext = os.path.splitext(file_path).lower()\n",
    "            \n",
    "            if file_ext in direct_process_exts:\n",
    "                print(f\"{file_ext} 형식, 변환 없이 인식 처리\")\n",
    "                audio_filepath = file_path\n",
    "            else:\n",
    "                print(f\"{file_ext} 형식, WAV PCM으로 변환 수행\")\n",
    "                audio_converted = \"audio_converted.wav\"\n",
    "                sound = AudioSegment.from_file(file_path)\n",
    "                sound = sound.set_channels(1).set_frame_rate(16000)\n",
    "                sound.export(audio_converted, format=\"wav\", parameters=[\"-ac\", \"1\", \"-ar\", \"16000\"])\n",
    "                audio_filepath = audio_converted\n",
    "            \n",
    "            # STT 처리\n",
    "            audio_input = speechsdk.audio.AudioConfig(filename=audio_filepath)\n",
    "            speech_recognizer = speechsdk.SpeechRecognizer(speech_config, audio_input)\n",
    "            \n",
    "            all_results = []\n",
    "            \n",
    "            def recognized_handler(evt):\n",
    "                if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "                    print(f\"✅ 인식: {evt.result.text}\")\n",
    "                    all_results.append(evt.result.text)\n",
    "            \n",
    "            def stop_handler(evt):\n",
    "                print(\"🛑 인식 세션 종료\")\n",
    "                speech_recognizer.stop_continuous_recognition()\n",
    "            \n",
    "            speech_recognizer.recognized.connect(recognized_handler)\n",
    "            speech_recognizer.session_stopped.connect(stop_handler)\n",
    "            speech_recognizer.canceled.connect(stop_handler)\n",
    "            \n",
    "            # 연속 인식 시작\n",
    "            speech_recognizer.start_continuous_recognition()\n",
    "            \n",
    "            # 오디오 길이 계산 및 대기\n",
    "            if os.path.exists(audio_filepath):\n",
    "                audio = AudioSegment.from_file(audio_filepath)\n",
    "                duration_sec = len(audio) / 1000.0\n",
    "                print(f\"⏱️ 인식할 오디오 길이: {duration_sec:.2f}초\")\n",
    "                time.sleep(duration_sec + 2)\n",
    "            \n",
    "            speech_recognizer.stop_continuous_recognition()\n",
    "            \n",
    "            # 결과 처리\n",
    "            if all_results:\n",
    "                original_text = \" \".join(all_results)\n",
    "                print(f\"\\n📝 원본 텍스트 ({INPUT_LANGUAGE}): {original_text}\")\n",
    "                \n",
    "                # 번역\n",
    "                result = translate_text(original_text)\n",
    "                if result.get(\"translated_text\"):\n",
    "                    translated = result[\"translated_text\"]\n",
    "                    detected = result.get(\"detected_language\", \"unknown\")\n",
    "                    print(f\"🔄 번역 결과 ({OUTPUT_LANGUAGE}): {translated}\")\n",
    "                    print(f\"   감지된 언어: {detected}\")\n",
    "                    \n",
    "                    # TTS 출력\n",
    "                    speak_text(translated, \"speaker\")\n",
    "                else:\n",
    "                    print(\"❌ 번역 실패\")\n",
    "            else:\n",
    "                print(\"❌ 인식된 텍스트가 없습니다.\")\n",
    "            \n",
    "        elif choice == \"0\":\n",
    "            print(\"👋 프로그램을 종료합니다.\")\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ 잘못된 선택입니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
