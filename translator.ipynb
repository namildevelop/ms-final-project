{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d9700",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from azure.ai.translation.text import TextTranslationClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from pydub import AudioSegment\n",
    "from datetime import datetime\n",
    "\n",
    "# 환경변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# Azure 설정\n",
    "speech_api_key = os.getenv(\"SPEECH_API_KEY\")\n",
    "region = os.getenv(\"SPEECH_REGION\")\n",
    "translator_api_key = os.getenv(\"TRANSLATOR_API_KEY\")\n",
    "translator_region = os.getenv(\"TRANSLATOR_REGION\")\n",
    "translator_endpoint = os.getenv(\"TRANSLATOR_ENDPOINT\")\n",
    "\n",
    "# FFmpeg 경로 설정\n",
    "AudioSegment.converter = r\"C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "AudioSegment.ffprobe = r\"C:\\\\ffmpeg\\\\bin\\\\ffprobe.exe\"\n",
    "\n",
    "# ==================== 언어 설정 ====================\n",
    "# 여기서 입력 언어와 출력 언어를 설정하세요\n",
    "INPUT_LANGUAGE = \"한국어\"      # STT 입력 언어\n",
    "OUTPUT_LANGUAGE = \"영어\"       # 번역 출력 + TTS 출력 언어\n",
    "\n",
    "# 언어 매핑 테이블\n",
    "LANGUAGE_MAPPING = {\n",
    "    # 언어명: (STT코드, 번역코드, TTS음성)\n",
    "    \"한국어\": (\"ko-KR\", \"ko\", \"ko-KR-SunHiNeural\"),\n",
    "    \"영어\": (\"en-US\", \"en\", \"en-US-AvaMultilingualNeural\"),\n",
    "    \"중국어(간체)\": (\"zh-CN\", \"zh-Hans\", \"zh-CN-XiaoxiaoNeural\"),\n",
    "    \"일본어\": (\"ja-JP\", \"ja\", \"ja-JP-NanamiNeural\"),\n",
    "    \"독일어\": (\"de-DE\", \"de\", \"de-DE-KatjaNeural\"),\n",
    "    \"프랑스어\": (\"fr-FR\", \"fr\", \"fr-FR-DeniseNeural\"),\n",
    "    \"스페인어\": (\"es-ES\", \"es\", \"es-ES-ElviraNeural\"),\n",
    "    \"이탈리아어\": (\"it-IT\", \"it\", \"it-IT-IsabellaNeural\"),\n",
    "    \"러시아어\": (\"ru-RU\", \"ru\", \"ru-RU-DariyaNeural\"),\n",
    "    \"포르투갈어\": (\"pt-BR\", \"pt\", \"pt-BR-FranciscaNeural\"),\n",
    "    \"중국어(번체)\": (\"zh-HK\", \"zh-Hant\", \"zh-HK-HiuGaaiNeural\"),\n",
    "    \"네덜란드어\": (\"nl-NL\", \"nl\", \"nl-NL-FennaNeural\"),\n",
    "    \"폴란드어\": (\"pl-PL\", \"pl\", \"pl-PL-AgnieszkaNeural\"),\n",
    "    \"스웨덴어\": (\"sv-SE\", \"sv\", \"sv-SE-SofieNeural\"),\n",
    "    \"덴마크어\": (\"da-DK\", \"da\", \"da-DK-ChristelNeural\"),\n",
    "    \"핀란드어\": (\"fi-FI\", \"fi\", \"fi-FI-SelmaNeural\"),\n",
    "    \"노르웨이어\": (\"nb-NO\", \"nb\", \"nb-NO-PernilleNeural\"),\n",
    "    \"체코어\": (\"cs-CZ\", \"cs\", \"cs-CZ-VlastaNeural\"),\n",
    "    \"헝가리어\": (\"hu-HU\", \"hu\", \"hu-HU-NoemiNeural\"),\n",
    "    \"아랍어\": (\"ar-SA\", \"ar\", \"ar-SA-ZariyahNeural\"),\n",
    "    \"힌디어\": (\"hi-IN\", \"hi\", \"hi-IN-SwaraNeural\"),\n",
    "    \"터키어\": (\"tr-TR\", \"tr\", \"tr-TR-EmelNeural\"),\n",
    "    \"우크라이나어\": (\"uk-UA\", \"uk\", \"uk-UA-PolinaNeural\"),\n",
    "}\n",
    "\n",
    "# 설정한 언어에서 코드 추출\n",
    "INPUT_STT_CODE, INPUT_TRANSLATE_CODE, INPUT_TTS_VOICE = LANGUAGE_MAPPING[INPUT_LANGUAGE]\n",
    "OUTPUT_STT_CODE, OUTPUT_TRANSLATE_CODE, OUTPUT_TTS_VOICE = LANGUAGE_MAPPING[OUTPUT_LANGUAGE]\n",
    "\n",
    "print(f\"🎤 입력 언어: {INPUT_LANGUAGE} ({INPUT_STT_CODE})\")\n",
    "print(f\"🔄 출력 언어: {OUTPUT_LANGUAGE} ({OUTPUT_TRANSLATE_CODE})\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ==================== STT 클래스 ====================\n",
    "class AzureSTT:\n",
    "    def __init__(self):\n",
    "        self.speech_config = speechsdk.SpeechConfig(subscription=speech_api_key, region=region)\n",
    "        self.speech_config.speech_recognition_language = INPUT_STT_CODE\n",
    "        self.recognizer = None\n",
    "        self.is_listening = False\n",
    "        self.text_updater = TextUpdater()\n",
    "    \n",
    "    def start_continuous_recognition(self):\n",
    "        if self.is_listening:\n",
    "            return\n",
    "        \n",
    "        self.text_updater.clear()\n",
    "        \n",
    "        audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "        self.recognizer = speechsdk.SpeechRecognizer(self.speech_config, audio_config)\n",
    "        \n",
    "        def recognized_handler(evt):\n",
    "            if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech and evt.result.text.strip():\n",
    "                self.text_updater.update_text(evt.result.text.strip(), is_partial=False)\n",
    "                print(f\"✅ STT 인식: {evt.result.text.strip()}\")\n",
    "        \n",
    "        def recognizing_handler(evt):\n",
    "            if evt.result.reason == speechsdk.ResultReason.RecognizingSpeech and evt.result.text.strip():\n",
    "                self.text_updater.update_text(f\"인식중... {evt.result.text.strip()}\", is_partial=True)\n",
    "        \n",
    "        self.recognizer.recognized.connect(recognized_handler)\n",
    "        self.recognizer.recognizing.connect(recognizing_handler)\n",
    "        \n",
    "        self.recognizer.start_continuous_recognition()\n",
    "        self.is_listening = True\n",
    "        print(f\"🎤 {INPUT_LANGUAGE} 실시간 음성 인식 시작\")\n",
    "    \n",
    "    def stop_continuous_recognition(self):\n",
    "        if not self.is_listening or self.recognizer is None:\n",
    "            return\n",
    "        \n",
    "        self.recognizer.stop_continuous_recognition()\n",
    "        self.is_listening = False\n",
    "        self.recognizer = None\n",
    "        print(\"🛑 음성 인식 중지\")\n",
    "    \n",
    "    def get_current_text(self):\n",
    "        return self.text_updater.get_full_text()\n",
    "    \n",
    "    def clear_text(self):\n",
    "        self.text_updater.clear()\n",
    "\n",
    "class TextUpdater:\n",
    "    def __init__(self):\n",
    "        self.text = \"\"\n",
    "        self.partial = \"\"\n",
    "    \n",
    "    def update_text(self, new_text, is_partial=False):\n",
    "        if is_partial:\n",
    "            self.partial = new_text\n",
    "        else:\n",
    "            self.text += new_text + \" \"\n",
    "            self.partial = \"\"\n",
    "    \n",
    "    def get_full_text(self):\n",
    "        if self.partial:\n",
    "            return f\"{self.text}\\n\\n🎤 {self.partial}\"\n",
    "        return self.text\n",
    "    \n",
    "    def clear(self):\n",
    "        self.text = \"\"\n",
    "        self.partial = \"\"\n",
    "\n",
    "# ==================== 번역 클래스 ====================\n",
    "class AzureTranslator:\n",
    "    def __init__(self):\n",
    "        self.credential = AzureKeyCredential(translator_api_key)\n",
    "        self.translator = TextTranslationClient(\n",
    "            credential=self.credential,\n",
    "            endpoint=translator_endpoint,\n",
    "            region=translator_region\n",
    "        )\n",
    "    \n",
    "    def translate_text(self, text, target_language=OUTPUT_TRANSLATE_CODE, source_language=None):\n",
    "        try:\n",
    "            if source_language is None:\n",
    "                response = self.translator.translate(\n",
    "                    body=[{\"text\": text}],\n",
    "                    to_language=[target_language]\n",
    "                )\n",
    "            else:\n",
    "                response = self.translator.translate(\n",
    "                    body=[{\"text\": text}],\n",
    "                    to_language=[target_language],\n",
    "                    from_language=source_language\n",
    "                )\n",
    "            \n",
    "            translation_result = response[0]\n",
    "            translated_text = translation_result.translations[0].text\n",
    "            \n",
    "            detected_language = None\n",
    "            confidence = None\n",
    "            if hasattr(translation_result, 'detected_language') and translation_result.detected_language:\n",
    "                detected_language = translation_result.detected_language.language\n",
    "                confidence = translation_result.detected_language.score\n",
    "            \n",
    "            return {\n",
    "                \"original_text\": text,\n",
    "                \"translated_text\": translated_text,\n",
    "                \"target_language\": target_language,\n",
    "                \"detected_language\": detected_language,\n",
    "                \"confidence\": confidence\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 번역 오류: {e}\")\n",
    "            return {\"original_text\": text, \"translated_text\": None, \"error\": str(e)}\n",
    "\n",
    "# ==================== TTS 클래스 ====================\n",
    "class AzureTTS:\n",
    "    def __init__(self):\n",
    "        self.speech_config = speechsdk.SpeechConfig(subscription=speech_api_key, region=region)\n",
    "        self.speech_config.speech_synthesis_voice_name = OUTPUT_TTS_VOICE\n",
    "        self.synthesizer = None\n",
    "    \n",
    "    def speak_text(self, text, output_method=\"speaker\"):\n",
    "        if not text.strip():\n",
    "            print(\"❌ TTS할 텍스트가 없습니다.\")\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            if output_method == \"speaker\":\n",
    "                return self._speak_to_speaker(text)\n",
    "            elif output_method == \"file\":\n",
    "                return self._speak_to_file(text)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ TTS 오류: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _speak_to_speaker(self, text):\n",
    "        print(f\"🔊 [{OUTPUT_LANGUAGE}] TTS 출력: {text}\")\n",
    "        \n",
    "        audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "        self.synthesizer = speechsdk.SpeechSynthesizer(self.speech_config, audio_config)\n",
    "        \n",
    "        result = self.synthesizer.speak_text_async(text).get()\n",
    "        \n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(\"✅ TTS 출력 완료\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ TTS 실패: {result.cancellation_details.reason}\")\n",
    "            return False\n",
    "    \n",
    "    def _speak_to_file(self, text):\n",
    "        now = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "        filename = f\"tts_output_{now}.wav\"\n",
    "        \n",
    "        print(f\"💾 [{OUTPUT_LANGUAGE}] TTS 파일 저장: {filename}\")\n",
    "        \n",
    "        audio_config = speechsdk.audio.AudioOutputConfig(filename=filename)\n",
    "        self.synthesizer = speechsdk.SpeechSynthesizer(self.speech_config, audio_config)\n",
    "        \n",
    "        result = self.synthesizer.speak_text_async(text).get()\n",
    "        \n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(f\"✅ 파일 저장 완료: {filename}\")\n",
    "            return filename\n",
    "        else:\n",
    "            print(f\"❌ 파일 저장 실패: {result.cancellation_details.reason}\")\n",
    "            return None\n",
    "\n",
    "# ==================== 통합 파이프라인 클래스 ====================\n",
    "class STTTranslateTTSPipeline:\n",
    "    def __init__(self):\n",
    "        self.stt = AzureSTT()\n",
    "        self.translator = AzureTranslator()\n",
    "        self.tts = AzureTTS()\n",
    "    \n",
    "    def start_realtime_pipeline(self, auto_translate=True, auto_tts=True, tts_method=\"speaker\"):\n",
    "        \"\"\"실시간 STT → 번역 → TTS 파이프라인\"\"\"\n",
    "        print(\"🚀 실시간 파이프라인 시작\")\n",
    "        print(f\"   입력: {INPUT_LANGUAGE} → 출력: {OUTPUT_LANGUAGE}\")\n",
    "        print(\"   'q' + Enter로 종료\\n\")\n",
    "        \n",
    "        self.stt.start_continuous_recognition()\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                user_input = input()\n",
    "                if user_input.lower() == 'q':\n",
    "                    break\n",
    "                \n",
    "                # 현재 인식된 텍스트 가져오기\n",
    "                current_text = self.stt.get_current_text()\n",
    "                if not current_text or \"🎤\" in current_text:\n",
    "                    continue\n",
    "                \n",
    "                print(f\"\\n📝 원본 텍스트: {current_text}\")\n",
    "                \n",
    "                # 자동 번역\n",
    "                if auto_translate and current_text.strip():\n",
    "                    result = self.translator.translate_text(current_text)\n",
    "                    if result.get(\"translated_text\"):\n",
    "                        translated = result[\"translated_text\"]\n",
    "                        detected = result.get(\"detected_language\", \"unknown\")\n",
    "                        print(f\"🔄 번역 결과: {translated} (감지언어: {detected})\")\n",
    "                        \n",
    "                        # 자동 TTS\n",
    "                        if auto_tts:\n",
    "                            self.tts.speak_text(translated, tts_method)\n",
    "                \n",
    "                self.stt.clear_text()\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n사용자가 중단했습니다.\")\n",
    "        finally:\n",
    "            self.stt.stop_continuous_recognition()\n",
    "    \n",
    "    def process_file(self, file_path, tts_method=\"speaker\"):\n",
    "        \"\"\"파일에서 STT → 번역 → TTS 처리\"\"\"\n",
    "        print(f\"📁 파일 처리: {file_path}\")\n",
    "        \n",
    "        # 파일 STT 처리\n",
    "        recognized_text = self._recognize_file(file_path)\n",
    "        if not recognized_text:\n",
    "            print(\"❌ 파일 인식 실패\")\n",
    "            return\n",
    "        \n",
    "        print(f\"📝 원본 텍스트: {recognized_text}\")\n",
    "        \n",
    "        # 번역\n",
    "        result = self.translator.translate_text(recognized_text)\n",
    "        if result.get(\"translated_text\"):\n",
    "            translated = result[\"translated_text\"]\n",
    "            print(f\"🔄 번역 결과: {translated}\")\n",
    "            \n",
    "            # TTS 출력\n",
    "            self.tts.speak_text(translated, tts_method)\n",
    "        else:\n",
    "            print(\"❌ 번역 실패\")\n",
    "    \n",
    "    def _recognize_file(self, file_path):\n",
    "        \"\"\"파일 음성 인식\"\"\"\n",
    "        if not os.path.exists(file_path):\n",
    "            return None\n",
    "        \n",
    "        # 파일 형식 변환 (필요시)\n",
    "        file_ext = os.path.splitext(file_path)[1].lower()\n",
    "        if file_ext not in [\".wav\", \".pcm\", \".wave\", \".flac\"]:\n",
    "            audio_path = \"temp_converted.wav\"\n",
    "            sound = AudioSegment.from_file(file_path)\n",
    "            sound = sound.set_channels(1).set_frame_rate(16000)\n",
    "            sound.export(audio_path, format=\"wav\")\n",
    "        else:\n",
    "            audio_path = file_path\n",
    "        \n",
    "        # 음성 인식\n",
    "        speech_config = speechsdk.SpeechConfig(subscription=speech_api_key, region=region)\n",
    "        speech_config.speech_recognition_language = INPUT_STT_CODE\n",
    "        audio_config = speechsdk.audio.AudioConfig(filename=audio_path)\n",
    "        recognizer = speechsdk.SpeechRecognizer(speech_config, audio_config)\n",
    "        \n",
    "        result = recognizer.recognize_once()\n",
    "        if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "            return result.text\n",
    "        return None\n",
    "\n",
    "# ==================== 메인 실행 ====================\n",
    "if __name__ == \"__main__\":\n",
    "    # 파이프라인 생성\n",
    "    pipeline = STTTranslateTTSPipeline()\n",
    "    \n",
    "    print(\"🎯 Azure STT → 번역 → TTS 통합 시스템\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"1. 실시간 처리 (마이크)\")\n",
    "    print(\"2. 파일 처리\")\n",
    "    print(\"0. 종료\")\n",
    "    \n",
    "    while True:\n",
    "        choice = input(\"\\n선택하세요 > \").strip()\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            # 실시간 파이프라인\n",
    "            pipeline.start_realtime_pipeline(\n",
    "                auto_translate=True, \n",
    "                auto_tts=True, \n",
    "                tts_method=\"speaker\"  # 또는 \"file\"\n",
    "            )\n",
    "            \n",
    "        elif choice == \"2\":\n",
    "            # 파일 처리\n",
    "            file_path = input(\"오디오 파일 경로 입력 > \").strip()\n",
    "            pipeline.process_file(file_path, tts_method=\"speaker\")\n",
    "            \n",
    "        elif choice == \"0\":\n",
    "            print(\"프로그램을 종료합니다.\")\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ 잘못된 선택입니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
