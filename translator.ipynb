{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d9700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤ ì…ë ¥ ì–¸ì–´: ì˜ì–´ (en-US)\n",
      "ğŸ”„ ì¶œë ¥ ì–¸ì–´: í•œêµ­ì–´ (ko)\n",
      "==================================================\n",
      "ğŸ¯ Azure STT â†’ ë²ˆì—­ â†’ TTS í†µí•© ì‹œìŠ¤í…œ\n",
      "==================================================\n",
      "1. ë§ˆì´í¬ ì‹¤ì‹œê°„ ì²˜ë¦¬ (ê³„ì† ì‹¤í–‰)\n",
      "2. ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬\n",
      "0. ì¢…ë£Œ\n",
      "ğŸ¤ ì˜ì–´ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œì‘\n",
      "ë§ì”€í•˜ì‹œë©´ ìë™ìœ¼ë¡œ ë²ˆì—­ë˜ê³  ìŒì„± ì¶œë ¥ë©ë‹ˆë‹¤.\n",
      "ì¢…ë£Œí•˜ë ¤ë©´ 'q' ë˜ëŠ” 'quit'ì„ ì…ë ¥í•˜ì„¸ìš”.\n",
      "--------------------------------------------------\n",
      "ğŸ‘‹ ì‚¬ìš©ìê°€ ì¢…ë£Œë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ›‘ ìŒì„± ì¸ì‹ì„ ì¤‘ì§€í•©ë‹ˆë‹¤...\n",
      "ğŸ›‘ ì„¸ì…˜ ì¢…ë£Œ: SessionEventArgs(session_id=3663f456a6fd4dedb769e9cc561cf29b)\n",
      "ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import threading\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from azure.ai.translation.text import TextTranslationClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from pydub import AudioSegment\n",
    "from datetime import datetime\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# Azure ì„¤ì •\n",
    "speech_api_key = os.getenv(\"SPEECH_API_KEY\")\n",
    "region = os.getenv(\"SPEECH_REGION\")\n",
    "translator_api_key = os.getenv(\"TRANSLATOR_API_KEY\")\n",
    "translator_region = os.getenv(\"TRANSLATOR_REGION\")\n",
    "translator_endpoint = os.getenv(\"TRANSLATOR_ENDPOINT\")\n",
    "\n",
    "# ==================== ì–¸ì–´ ì„¤ì • ====================\n",
    "INPUT_LANGUAGE = \"ì˜ì–´\"      # STT ì…ë ¥ ì–¸ì–´\n",
    "OUTPUT_LANGUAGE = \"í•œêµ­ì–´\"       # ë²ˆì—­ ì¶œë ¥ + TTS ì¶œë ¥ ì–¸ì–´\n",
    "\n",
    "# ì–¸ì–´ ë§¤í•‘ í…Œì´ë¸”\n",
    "LANGUAGE_MAPPING = {\n",
    "    \"í•œêµ­ì–´\": (\"ko-KR\", \"ko\", \"ko-KR-SunHiNeural\"),\n",
    "    \"ì˜ì–´\": (\"en-US\", \"en\", \"en-US-AvaMultilingualNeural\"),\n",
    "    \"ì¤‘êµ­ì–´(ê°„ì²´)\": (\"zh-CN\", \"zh-Hans\", \"zh-CN-XiaoxiaoNeural\"),\n",
    "    \"ì¼ë³¸ì–´\": (\"ja-JP\", \"ja\", \"ja-JP-NanamiNeural\"),\n",
    "    \"ë…ì¼ì–´\": (\"de-DE\", \"de\", \"de-DE-KatjaNeural\"),\n",
    "    \"í”„ë‘ìŠ¤ì–´\": (\"fr-FR\", \"fr\", \"fr-FR-DeniseNeural\"),\n",
    "    \"ìŠ¤í˜ì¸ì–´\": (\"es-ES\", \"es\", \"es-ES-ElviraNeural\"),\n",
    "    \"ì´íƒˆë¦¬ì•„ì–´\": (\"it-IT\", \"it\", \"it-IT-IsabellaNeural\"),\n",
    "    \"ëŸ¬ì‹œì•„ì–´\": (\"ru-RU\", \"ru\", \"ru-RU-DariyaNeural\"),\n",
    "    \"í¬ë¥´íˆ¬ê°ˆì–´\": (\"pt-BR\", \"pt\", \"pt-BR-FranciscaNeural\"),\n",
    "}\n",
    "\n",
    "INPUT_STT_CODE, INPUT_TRANSLATE_CODE, INPUT_TTS_VOICE = LANGUAGE_MAPPING[INPUT_LANGUAGE]\n",
    "OUTPUT_STT_CODE, OUTPUT_TRANSLATE_CODE, OUTPUT_TTS_VOICE = LANGUAGE_MAPPING[OUTPUT_LANGUAGE]\n",
    "\n",
    "print(f\"ğŸ¤ ì…ë ¥ ì–¸ì–´: {INPUT_LANGUAGE} ({INPUT_STT_CODE})\")\n",
    "print(f\"ğŸ”„ ì¶œë ¥ ì–¸ì–´: {OUTPUT_LANGUAGE} ({OUTPUT_TRANSLATE_CODE})\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# STT ì„¤ì •\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_api_key, region=region)\n",
    "speech_config.speech_recognition_language = INPUT_STT_CODE\n",
    "\n",
    "# FFmpeg ê²½ë¡œ ì„¤ì •\n",
    "AudioSegment.converter = r\"C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "AudioSegment.ffprobe = r\"C:\\\\ffmpeg\\\\bin\\\\ffprobe.exe\"\n",
    "\n",
    "# ë²ˆì—­ê¸° ì„¤ì •\n",
    "translator_credential = AzureKeyCredential(translator_api_key)\n",
    "translator = TextTranslationClient(\n",
    "    credential=translator_credential,\n",
    "    endpoint=translator_endpoint,\n",
    "    region=translator_region\n",
    ")\n",
    "\n",
    "# TTS ì„¤ì •\n",
    "tts_config = speechsdk.SpeechConfig(subscription=speech_api_key, region=region)\n",
    "tts_config.speech_synthesis_voice_name = OUTPUT_TTS_VOICE\n",
    "\n",
    "# ==================== ë²ˆì—­ í•¨ìˆ˜ ====================\n",
    "def translate_text(text, target_language=OUTPUT_TRANSLATE_CODE):\n",
    "    \"\"\"í…ìŠ¤íŠ¸ ë²ˆì—­\"\"\"\n",
    "    try:\n",
    "        response = translator.translate(\n",
    "            body=[{\"text\": text}],\n",
    "            to_language=[target_language]\n",
    "        )\n",
    "        \n",
    "        # ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì´ë¯€ë¡œ ì˜¬ë°”ë¥´ê²Œ ì ‘ê·¼\n",
    "        if isinstance(response, list) and len(response) > 0:\n",
    "            translation_result = response\n",
    "            \n",
    "            # translationsë„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ\n",
    "            if hasattr(translation_result, 'translations') and len(translation_result.translations) > 0:\n",
    "                translated_text = translation_result.translations.text\n",
    "            else:\n",
    "                print(f\"âŒ ë²ˆì—­ ê²°ê³¼ êµ¬ì¡° ì˜¤ë¥˜: {translation_result}\")\n",
    "                return {\"original_text\": text, \"translated_text\": None, \"error\": \"Invalid response structure\"}\n",
    "            \n",
    "            # ì–¸ì–´ ê°ì§€ ê²°ê³¼\n",
    "            detected_language = None\n",
    "            if hasattr(translation_result, 'detected_language') and translation_result.detected_language:\n",
    "                detected_language = translation_result.detected_language.language\n",
    "            \n",
    "            return {\n",
    "                \"original_text\": text,\n",
    "                \"translated_text\": translated_text,\n",
    "                \"detected_language\": detected_language\n",
    "            }\n",
    "        else:\n",
    "            print(f\"âŒ ë¹ˆ ì‘ë‹µ: {response}\")\n",
    "            return {\"original_text\": text, \"translated_text\": None, \"error\": \"Empty response\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë²ˆì—­ ì˜¤ë¥˜: {e}\")\n",
    "        print(f\"   ì›ë³¸ í…ìŠ¤íŠ¸: {text}\")\n",
    "        return {\"original_text\": text, \"translated_text\": None, \"error\": str(e)}\n",
    "\n",
    "\n",
    "# ==================== TTS í•¨ìˆ˜ ====================\n",
    "def speak_text(text, output_method=\"speaker\"):\n",
    "    \"\"\"TTS ìŒì„± ì¶œë ¥\"\"\"\n",
    "    if not text.strip():\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if output_method == \"speaker\":\n",
    "            audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "        else:  # file\n",
    "            now = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "            filename = f\"tts_output_{now}.wav\"\n",
    "            audio_config = speechsdk.audio.AudioOutputConfig(filename=filename)\n",
    "        \n",
    "        synthesizer = speechsdk.SpeechSynthesizer(tts_config, audio_config)\n",
    "        result = synthesizer.speak_text_async(text).get()\n",
    "        \n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            if output_method == \"speaker\":\n",
    "                print(f\"ğŸ”Š [{OUTPUT_LANGUAGE}] TTS ì¶œë ¥ ì™„ë£Œ\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"ğŸ’¾ [{OUTPUT_LANGUAGE}] íŒŒì¼ ì €ì¥: {filename}\")\n",
    "                return filename\n",
    "        else:\n",
    "            print(f\"âŒ TTS ì‹¤íŒ¨: {result.cancellation_details.reason}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ TTS ì˜¤ë¥˜: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==================== ì‹¤ì‹œê°„ ì—°ì† ìŒì„± ì¸ì‹ (ì‚¬ìš©ì ì…ë ¥ê¹Œì§€ ê³„ì† ì‹¤í–‰) ====================\n",
    "def continuous_microphone_recognition():\n",
    "    \"\"\"ì‚¬ìš©ìê°€ ì¢…ë£Œ ëª…ë ¹ì„ ì…ë ¥í•˜ê¸° ì „ê¹Œì§€ ê³„ì† ì‹¤í–‰ë˜ëŠ” ìŒì„± ì¸ì‹\"\"\"\n",
    "    \n",
    "    print(f\"ğŸ¤ {INPUT_LANGUAGE} ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œì‘\")\n",
    "    print(\"ë§ì”€í•˜ì‹œë©´ ìë™ìœ¼ë¡œ ë²ˆì—­ë˜ê³  ìŒì„± ì¶œë ¥ë©ë‹ˆë‹¤.\")\n",
    "    print(\"ì¢…ë£Œí•˜ë ¤ë©´ 'q' ë˜ëŠ” 'quit'ì„ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # ë§ˆì´í¬ ì…ë ¥ ì„¤ì •\n",
    "    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config, audio_config)\n",
    "    \n",
    "    # ì¸ì‹ ì™„ë£Œ í”Œë˜ê·¸\n",
    "    done = False\n",
    "    \n",
    "    def recognized_handler(evt):\n",
    "        \"\"\"ìŒì„± ì¸ì‹ ì™„ë£Œ ì‹œ ìë™ìœ¼ë¡œ ë²ˆì—­ ë° TTS ì‹¤í–‰\"\"\"\n",
    "        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech and evt.result.text.strip():\n",
    "            original_text = evt.result.text.strip()\n",
    "            print(f\"\\nâœ… ì¸ì‹: {original_text}\")\n",
    "            \n",
    "            # ìë™ ë²ˆì—­\n",
    "            result = translate_text(original_text)\n",
    "            if result.get(\"translated_text\"):\n",
    "                translated = result[\"translated_text\"]\n",
    "                detected = result.get(\"detected_language\", \"unknown\")\n",
    "                print(f\"ğŸ”„ ë²ˆì—­: {translated} (ê°ì§€ì–¸ì–´: {detected})\")\n",
    "                \n",
    "                # ìë™ TTS\n",
    "                speak_text(translated, \"speaker\")\n",
    "            else:\n",
    "                print(\"âŒ ë²ˆì—­ ì‹¤íŒ¨\")\n",
    "            \n",
    "            print(\"-\" * 30)\n",
    "    \n",
    "    def recognizing_handler(evt):\n",
    "        \"\"\"ì‹¤ì‹œê°„ ì¸ì‹ ì¤‘ (ë¶€ë¶„ ê²°ê³¼)\"\"\"\n",
    "        if evt.result.reason == speechsdk.ResultReason.RecognizingSpeech and evt.result.text.strip():\n",
    "            print(f\"ğŸ¤ ì¸ì‹ì¤‘: {evt.result.text.strip()}\", end='\\r')\n",
    "    \n",
    "    def stop_handler(evt):\n",
    "        \"\"\"ì„¸ì…˜ ì¢…ë£Œ í•¸ë“¤ëŸ¬\"\"\"\n",
    "        nonlocal done\n",
    "        print(f\"ğŸ›‘ ì„¸ì…˜ ì¢…ë£Œ: {evt}\")\n",
    "        done = True\n",
    "    \n",
    "    def canceled_handler(evt):\n",
    "        \"\"\"ì·¨ì†Œ í•¸ë“¤ëŸ¬\"\"\"\n",
    "        nonlocal done\n",
    "        print(f\"âŒ ì¸ì‹ ì·¨ì†Œ: {evt}\")\n",
    "        done = True\n",
    "    \n",
    "    # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°\n",
    "    speech_recognizer.recognized.connect(recognized_handler)\n",
    "    speech_recognizer.recognizing.connect(recognizing_handler)\n",
    "    speech_recognizer.session_stopped.connect(stop_handler)\n",
    "    speech_recognizer.canceled.connect(canceled_handler)\n",
    "    \n",
    "    # ì—°ì† ì¸ì‹ ì‹œì‘\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    \n",
    "    # ì‚¬ìš©ì ì…ë ¥ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬\n",
    "    def wait_for_user_input():\n",
    "        nonlocal done\n",
    "        while not done:\n",
    "            try:\n",
    "                user_input = input().strip().lower()\n",
    "                if user_input in ['q', 'quit', 'exit', 'ì¢…ë£Œ']:\n",
    "                    print(\"ğŸ‘‹ ì‚¬ìš©ìê°€ ì¢…ë£Œë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.\")\n",
    "                    done = True\n",
    "                    break\n",
    "            except (EOFError, KeyboardInterrupt):\n",
    "                print(\"\\nğŸ‘‹ í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                done = True\n",
    "                break\n",
    "    \n",
    "    # ì…ë ¥ ëŒ€ê¸° ìŠ¤ë ˆë“œ ì‹œì‘\n",
    "    input_thread = threading.Thread(target=wait_for_user_input, daemon=True)\n",
    "    input_thread.start()\n",
    "    \n",
    "    # ë©”ì¸ ë£¨í”„ (doneì´ Trueê°€ ë  ë•Œê¹Œì§€ ê³„ì† ì‹¤í–‰)\n",
    "    try:\n",
    "        while not done:\n",
    "            time.sleep(0.5)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nğŸ‘‹ í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        done = True\n",
    "    finally:\n",
    "        # ì¸ì‹ ì¤‘ì§€\n",
    "        print(\"ğŸ›‘ ìŒì„± ì¸ì‹ì„ ì¤‘ì§€í•©ë‹ˆë‹¤...\")\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "\n",
    "# ==================== ë””ë²„ê¹… ========================\n",
    "def translate_text_debug(text, target_language=OUTPUT_TRANSLATE_CODE):\n",
    "    \"\"\"ë””ë²„ê¹…ì„ ìœ„í•œ ë²ˆì—­ í•¨ìˆ˜\"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸ” ë²ˆì—­ ìš”ì²­: '{text}' -> {target_language}\")\n",
    "        \n",
    "        response = translator.translate(\n",
    "            body=[{\"text\": text}],\n",
    "            to_language=[target_language]\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ” ì‘ë‹µ íƒ€ì…: {type(response)}\")\n",
    "        print(f\"ğŸ” ì‘ë‹µ ë‚´ìš©: {response}\")\n",
    "        \n",
    "        if isinstance(response, list) and len(response) > 0:\n",
    "            translation_result = response\n",
    "            print(f\"ğŸ” ì²« ë²ˆì§¸ ê²°ê³¼: {type(translation_result)}\")\n",
    "            print(f\"ğŸ” ê²°ê³¼ ì†ì„±: {dir(translation_result)}\")\n",
    "            \n",
    "            if hasattr(translation_result, 'translations'):\n",
    "                print(f\"ğŸ” translations íƒ€ì…: {type(translation_result.translations)}\")\n",
    "                print(f\"ğŸ” translations ë‚´ìš©: {translation_result.translations}\")\n",
    "                \n",
    "                if len(translation_result.translations) > 0:\n",
    "                    translated_text = translation_result.translations.text\n",
    "                    print(f\"âœ… ë²ˆì—­ ì„±ê³µ: {translated_text}\")\n",
    "                    return translated_text\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ë²ˆì—­ ì˜¤ë¥˜ ìƒì„¸: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# ==================== ë©”ì¸ ì‹¤í–‰ë¶€ ====================\n",
    "def main():\n",
    "    print(\"ğŸ¯ Azure STT â†’ ë²ˆì—­ â†’ TTS í†µí•© ì‹œìŠ¤í…œ\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"1. ë§ˆì´í¬ ì‹¤ì‹œê°„ ì²˜ë¦¬ (ê³„ì† ì‹¤í–‰)\")\n",
    "    print(\"2. ì˜¤ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬\")\n",
    "    print(\"0. ì¢…ë£Œ\")\n",
    "    \n",
    "    while True:\n",
    "        choice = input(\"\\nì„ íƒí•˜ì„¸ìš” > \").strip()\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            # ì‹¤ì‹œê°„ ì—°ì† ì¸ì‹ (ì‚¬ìš©ìê°€ ì¢…ë£Œí•˜ê¸° ì „ê¹Œì§€ ê³„ì†)\n",
    "            continuous_microphone_recognition()\n",
    "            \n",
    "        elif choice == \"2\":\n",
    "            # íŒŒì¼ ì…ë ¥ ì²˜ë¦¬  \n",
    "            file_path = input(\"ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì…ë ¥ > \").strip()\n",
    "            \n",
    "            if not os.path.exists(file_path):\n",
    "                print(\"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"ğŸ“ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {file_path}\")\n",
    "            \n",
    "            # íŒŒì¼ í˜•ì‹ í™•ì¸ ë° ë³€í™˜\n",
    "            direct_process_exts = [\".wav\", \".pcm\", \".wave\", \".flac\"]\n",
    "            file_ext = os.path.splitext(file_path).lower()\n",
    "            \n",
    "            if file_ext in direct_process_exts:\n",
    "                print(f\"{file_ext} í˜•ì‹, ë³€í™˜ ì—†ì´ ì¸ì‹ ì²˜ë¦¬\")\n",
    "                audio_filepath = file_path\n",
    "            else:\n",
    "                print(f\"{file_ext} í˜•ì‹, WAV PCMìœ¼ë¡œ ë³€í™˜ ìˆ˜í–‰\")\n",
    "                audio_converted = \"audio_converted.wav\"\n",
    "                sound = AudioSegment.from_file(file_path)\n",
    "                sound = sound.set_channels(1).set_frame_rate(16000)\n",
    "                sound.export(audio_converted, format=\"wav\", parameters=[\"-ac\", \"1\", \"-ar\", \"16000\"])\n",
    "                audio_filepath = audio_converted\n",
    "            \n",
    "            # STT ì²˜ë¦¬\n",
    "            audio_input = speechsdk.audio.AudioConfig(filename=audio_filepath)\n",
    "            speech_recognizer = speechsdk.SpeechRecognizer(speech_config, audio_input)\n",
    "            \n",
    "            all_results = []\n",
    "            \n",
    "            def recognized_handler(evt):\n",
    "                if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "                    print(f\"âœ… ì¸ì‹: {evt.result.text}\")\n",
    "                    all_results.append(evt.result.text)\n",
    "            \n",
    "            def stop_handler(evt):\n",
    "                print(\"ğŸ›‘ ì¸ì‹ ì„¸ì…˜ ì¢…ë£Œ\")\n",
    "                speech_recognizer.stop_continuous_recognition()\n",
    "            \n",
    "            speech_recognizer.recognized.connect(recognized_handler)\n",
    "            speech_recognizer.session_stopped.connect(stop_handler)\n",
    "            speech_recognizer.canceled.connect(stop_handler)\n",
    "            \n",
    "            # ì—°ì† ì¸ì‹ ì‹œì‘\n",
    "            speech_recognizer.start_continuous_recognition()\n",
    "            \n",
    "            # ì˜¤ë””ì˜¤ ê¸¸ì´ ê³„ì‚° ë° ëŒ€ê¸°\n",
    "            if os.path.exists(audio_filepath):\n",
    "                audio = AudioSegment.from_file(audio_filepath)\n",
    "                duration_sec = len(audio) / 1000.0\n",
    "                print(f\"â±ï¸ ì¸ì‹í•  ì˜¤ë””ì˜¤ ê¸¸ì´: {duration_sec:.2f}ì´ˆ\")\n",
    "                time.sleep(duration_sec + 2)\n",
    "            \n",
    "            speech_recognizer.stop_continuous_recognition()\n",
    "            \n",
    "            # ê²°ê³¼ ì²˜ë¦¬\n",
    "            if all_results:\n",
    "                original_text = \" \".join(all_results)\n",
    "                print(f\"\\nğŸ“ ì›ë³¸ í…ìŠ¤íŠ¸ ({INPUT_LANGUAGE}): {original_text}\")\n",
    "                \n",
    "                # ë²ˆì—­\n",
    "                result = translate_text(original_text)\n",
    "                if result.get(\"translated_text\"):\n",
    "                    translated = result[\"translated_text\"]\n",
    "                    detected = result.get(\"detected_language\", \"unknown\")\n",
    "                    print(f\"ğŸ”„ ë²ˆì—­ ê²°ê³¼ ({OUTPUT_LANGUAGE}): {translated}\")\n",
    "                    print(f\"   ê°ì§€ëœ ì–¸ì–´: {detected}\")\n",
    "                    \n",
    "                    # TTS ì¶œë ¥\n",
    "                    speak_text(translated, \"speaker\")\n",
    "                else:\n",
    "                    print(\"âŒ ë²ˆì—­ ì‹¤íŒ¨\")\n",
    "            else:\n",
    "                print(\"âŒ ì¸ì‹ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            \n",
    "        elif choice == \"0\":\n",
    "            print(\"ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            print(\"âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
