{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d9700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 21\n",
      "python-dotenv could not parse statement starting at line 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 입력 언어: 한국어 (ko-KR)\n",
      "🔄 출력 언어: 영어 (en)\n",
      "==================================================\n",
      "🎯 Azure STT → 번역 → TTS 통합 시스템\n",
      "==================================================\n",
      "1. 실시간 처리 (마이크)\n",
      "2. 파일 처리\n",
      "0. 종료\n",
      "📁 파일 처리: audio1.wav\n",
      "📝 원본 텍스트: 데이터.\n",
      "🔄 번역 결과: Data.\n",
      "🔊 [영어] TTS 출력: Data.\n",
      "✅ TTS 출력 완료\n",
      "프로그램을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from azure.ai.translation.text import TextTranslationClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from pydub import AudioSegment\n",
    "from datetime import datetime\n",
    "\n",
    "# 환경변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# Azure 설정\n",
    "speech_api_key = os.getenv(\"SPEECH_API_KEY\")\n",
    "region = os.getenv(\"SPEECH_REGION\")\n",
    "translator_api_key = os.getenv(\"TRANSLATOR_API_KEY\")\n",
    "translator_region = os.getenv(\"TRANSLATOR_REGION\")\n",
    "translator_endpoint = os.getenv(\"TRANSLATOR_ENDPOINT\")\n",
    "\n",
    "# ==================== 언어 설정 ====================\n",
    "# 여기서 입력 언어와 출력 언어를 설정하세요\n",
    "INPUT_LANGUAGE = \"한국어\"      # STT 입력 언어\n",
    "OUTPUT_LANGUAGE = \"영어\"       # 번역 출력 + TTS 출력 언어\n",
    "\n",
    "# 언어 매핑 테이블\n",
    "LANGUAGE_MAPPING = {\n",
    "    \"한국어\": (\"ko-KR\", \"ko\", \"ko-KR-SunHiNeural\"),\n",
    "    \"영어\": (\"en-US\", \"en\", \"en-US-AvaMultilingualNeural\"),\n",
    "    \"중국어(간체)\": (\"zh-CN\", \"zh-Hans\", \"zh-CN-XiaoxiaoNeural\"),\n",
    "    \"일본어\": (\"ja-JP\", \"ja\", \"ja-JP-NanamiNeural\"),\n",
    "    \"독일어\": (\"de-DE\", \"de\", \"de-DE-KatjaNeural\"),\n",
    "    \"프랑스어\": (\"fr-FR\", \"fr\", \"fr-FR-DeniseNeural\"),\n",
    "    \"스페인어\": (\"es-ES\", \"es\", \"es-ES-ElviraNeural\"),\n",
    "    \"이탈리아어\": (\"it-IT\", \"it\", \"it-IT-IsabellaNeural\"),\n",
    "    \"러시아어\": (\"ru-RU\", \"ru\", \"ru-RU-DariyaNeural\"),\n",
    "    \"포르투갈어\": (\"pt-BR\", \"pt\", \"pt-BR-FranciscaNeural\"),\n",
    "}\n",
    "\n",
    "INPUT_STT_CODE, INPUT_TRANSLATE_CODE, INPUT_TTS_VOICE = LANGUAGE_MAPPING[INPUT_LANGUAGE]\n",
    "OUTPUT_STT_CODE, OUTPUT_TRANSLATE_CODE, OUTPUT_TTS_VOICE = LANGUAGE_MAPPING[OUTPUT_LANGUAGE]\n",
    "\n",
    "print(f\"🎤 입력 언어: {INPUT_LANGUAGE} ({INPUT_STT_CODE})\")\n",
    "print(f\"🔄 출력 언어: {OUTPUT_LANGUAGE} ({OUTPUT_TRANSLATE_CODE})\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# STT 설정\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_api_key, region=region)\n",
    "speech_config.speech_recognition_language = INPUT_STT_CODE\n",
    "\n",
    "# FFmpeg 경로 설정\n",
    "AudioSegment.converter = r\"C:\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "AudioSegment.ffprobe = r\"C:\\\\ffmpeg\\\\bin\\\\ffprobe.exe\"\n",
    "\n",
    "# 번역기 설정\n",
    "translator_credential = AzureKeyCredential(translator_api_key)\n",
    "translator = TextTranslationClient(\n",
    "    credential=translator_credential,\n",
    "    endpoint=translator_endpoint,\n",
    "    region=translator_region\n",
    ")\n",
    "\n",
    "# TTS 설정\n",
    "tts_config = speechsdk.SpeechConfig(subscription=speech_api_key, region=region)\n",
    "tts_config.speech_synthesis_voice_name = OUTPUT_TTS_VOICE\n",
    "\n",
    "# ==================== 번역 함수 ====================\n",
    "def translate_text(text, target_language=OUTPUT_TRANSLATE_CODE):\n",
    "    \"\"\"텍스트 번역\"\"\"\n",
    "    try:\n",
    "        response = translator.translate(\n",
    "            body=[{\"text\": text}],\n",
    "            to_language=[target_language]\n",
    "        )\n",
    "        \n",
    "        translation_result = response[0]\n",
    "        translated_text = translation_result.translations[0].text\n",
    "        \n",
    "        detected_language = None\n",
    "        if hasattr(translation_result, 'detected_language') and translation_result.detected_language:\n",
    "            detected_language = translation_result.detected_language.language\n",
    "        \n",
    "        return {\n",
    "            \"original_text\": text,\n",
    "            \"translated_text\": translated_text,\n",
    "            \"detected_language\": detected_language\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 번역 오류: {e}\")\n",
    "        return {\"original_text\": text, \"translated_text\": None, \"error\": str(e)}\n",
    "\n",
    "# ==================== TTS 함수 ====================\n",
    "def speak_text(text, output_method=\"speaker\"):\n",
    "    \"\"\"TTS 음성 출력\"\"\"\n",
    "    if not text.strip():\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        if output_method == \"speaker\":\n",
    "            audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "        else:  # file\n",
    "            now = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "            filename = f\"tts_output_{now}.wav\"\n",
    "            audio_config = speechsdk.audio.AudioOutputConfig(filename=filename)\n",
    "        \n",
    "        synthesizer = speechsdk.SpeechSynthesizer(tts_config, audio_config)\n",
    "        result = synthesizer.speak_text_async(text).get()\n",
    "        \n",
    "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            if output_method == \"speaker\":\n",
    "                print(f\"🔊 [{OUTPUT_LANGUAGE}] TTS 출력 완료\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"💾 [{OUTPUT_LANGUAGE}] 파일 저장: {filename}\")\n",
    "                return filename\n",
    "        else:\n",
    "            print(f\"❌ TTS 실패: {result.cancellation_details.reason}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"❌ TTS 오류: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==================== STT → 번역 → TTS 파이프라인 ====================\n",
    "def process_stt_results(all_results, auto_translate=True, auto_tts=True, tts_method=\"speaker\"):\n",
    "    \"\"\"STT 결과를 번역하고 TTS로 출력\"\"\"\n",
    "    if not all_results:\n",
    "        print(\"❌ 인식된 텍스트가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # STT 결과 합치기\n",
    "    original_text = \" \".join(all_results)\n",
    "    print(f\"\\n📝 원본 텍스트 ({INPUT_LANGUAGE}): {original_text}\")\n",
    "    \n",
    "    if auto_translate:\n",
    "        # 번역\n",
    "        result = translate_text(original_text)\n",
    "        if result.get(\"translated_text\"):\n",
    "            translated = result[\"translated_text\"]\n",
    "            detected = result.get(\"detected_language\", \"unknown\")\n",
    "            print(f\"🔄 번역 결과 ({OUTPUT_LANGUAGE}): {translated}\")\n",
    "            print(f\"   감지된 언어: {detected}\")\n",
    "            \n",
    "            if auto_tts:\n",
    "                # TTS 출력\n",
    "                speak_text(translated, tts_method)\n",
    "        else:\n",
    "            print(\"❌ 번역 실패\")\n",
    "\n",
    "# ==================== 메인 실행부 ====================\n",
    "def main():\n",
    "    print(\"🎯 Azure STT → 번역 → TTS 통합 시스템\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"1. 마이크 실시간 처리\")\n",
    "    print(\"2. 오디오 파일 처리\")\n",
    "    print(\"0. 종료\")\n",
    "    \n",
    "    while True:\n",
    "        choice = input(\"\\n선택하세요 > \").strip()\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            # 마이크 입력 처리\n",
    "            print(f\"🎤 {INPUT_LANGUAGE} 마이크 입력 시작 (10초 후 자동 종료)\")\n",
    "            \n",
    "            # 마이크 입력 설정\n",
    "            audio_input = speechsdk.audio.AudioConfig(use_default_microphone=True)\n",
    "            speech_recognizer = speechsdk.SpeechRecognizer(speech_config, audio_input)\n",
    "            \n",
    "            all_results = []\n",
    "            \n",
    "            def recognized_handler(evt):\n",
    "                if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "                    print(f\"✅ 인식: {evt.result.text}\")\n",
    "                    all_results.append(evt.result.text)\n",
    "            \n",
    "            def stop_handler(evt):\n",
    "                print(\"🛑 인식 세션 종료\")\n",
    "                speech_recognizer.stop_continuous_recognition()\n",
    "            \n",
    "            speech_recognizer.recognized.connect(recognized_handler)\n",
    "            speech_recognizer.session_stopped.connect(stop_handler)\n",
    "            speech_recognizer.canceled.connect(stop_handler)\n",
    "            \n",
    "            # 연속 인식 시작\n",
    "            speech_recognizer.start_continuous_recognition()\n",
    "            \n",
    "            try:\n",
    "                time.sleep(10)  # 10초 대기\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n사용자가 중단했습니다.\")\n",
    "            \n",
    "            speech_recognizer.stop_continuous_recognition()\n",
    "            \n",
    "            # 결과 처리\n",
    "            process_stt_results(all_results, auto_translate=True, auto_tts=True, tts_method=\"speaker\")\n",
    "            \n",
    "        elif choice == \"2\":\n",
    "            # 파일 입력 처리  \n",
    "            # file_path = input(\"오디오 파일 경로 입력 > \").strip()\n",
    "            file_path = \"audio1.wav\"\n",
    "            \n",
    "            if not os.path.exists(file_path):\n",
    "                print(\"❌ 파일이 존재하지 않습니다.\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"📁 파일 처리 중: {file_path}\")\n",
    "            \n",
    "            # 파일 형식 확인 및 변환\n",
    "            direct_process_exts = [\".wav\", \".pcm\", \".wave\", \".flac\"]\n",
    "            file_ext = os.path.splitext(file_path)[1].lower()\n",
    "            \n",
    "            if file_ext in direct_process_exts:\n",
    "                print(f\"{file_ext} 형식, 변환 없이 인식 처리\")\n",
    "                audio_filepath = file_path\n",
    "            else:\n",
    "                print(f\"{file_ext} 형식, WAV PCM으로 변환 수행\")\n",
    "                audio_converted = \"audio_converted.wav\"\n",
    "                sound = AudioSegment.from_file(file_path)\n",
    "                sound = sound.set_channels(1).set_frame_rate(16000)\n",
    "                sound.export(audio_converted, format=\"wav\", parameters=[\"-ac\", \"1\", \"-ar\", \"16000\"])\n",
    "                audio_filepath = audio_converted\n",
    "            \n",
    "            # STT 처리\n",
    "            audio_input = speechsdk.audio.AudioConfig(filename=audio_filepath)\n",
    "            speech_recognizer = speechsdk.SpeechRecognizer(speech_config, audio_input)\n",
    "            \n",
    "            all_results = []\n",
    "            \n",
    "            def recognized_handler(evt):\n",
    "                if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "                    print(f\"✅ 인식: {evt.result.text}\")\n",
    "                    all_results.append(evt.result.text)\n",
    "            \n",
    "            def stop_handler(evt):\n",
    "                print(\"🛑 인식 세션 종료\")\n",
    "                speech_recognizer.stop_continuous_recognition()\n",
    "            \n",
    "            speech_recognizer.recognized.connect(recognized_handler)\n",
    "            speech_recognizer.session_stopped.connect(stop_handler)\n",
    "            speech_recognizer.canceled.connect(stop_handler)\n",
    "            \n",
    "            # 연속 인식 시작\n",
    "            speech_recognizer.start_continuous_recognition()\n",
    "            \n",
    "            # 오디오 길이 계산 및 대기\n",
    "            if os.path.exists(audio_filepath):\n",
    "                audio = AudioSegment.from_file(audio_filepath)\n",
    "                duration_sec = len(audio) / 1000.0\n",
    "                print(f\"⏱️ 인식할 오디오 길이: {duration_sec:.2f}초\")\n",
    "                time.sleep(duration_sec + 2)\n",
    "            \n",
    "            speech_recognizer.stop_continuous_recognition()\n",
    "            \n",
    "            # 결과 처리\n",
    "            process_stt_results(all_results, auto_translate=True, auto_tts=True, tts_method=\"speaker\")\n",
    "            \n",
    "        elif choice == \"0\":\n",
    "            print(\"👋 프로그램을 종료합니다.\")\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ 잘못된 선택입니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
