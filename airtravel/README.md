

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

### 1. ë°±ì—”ë“œ (FastAPI)

- **AI ë°ì´í„° (`air_travel_back/ai_data/`)**
  - `index.faiss` â†’ FAISS ë²¡í„° ì¸ë±ìŠ¤
  - `meta_baked.json` â†’ ë©”íƒ€ë°ì´í„°
  - `yolov8n.pt` â†’ YOLOv8 ëª¨ë¸
  - ì„œìš¸ ê´€ê´‘ì§€ ì´ë¯¸ì§€ (ê´‘í™”ë¬¸, ì„¸ì¢…ëŒ€ì™•, ì´ìˆœì‹ , êµë³´ìƒëª…)

- **AI ëª¨ë¸ (`air_travel_back/app/ai_models/`)**
  - `clip_model.py` â†’ CLIP ëª¨ë¸ ë˜í¼
  - `yolo_model.py` â†’ YOLO ëª¨ë¸ ë˜í¼
  - `label_mapping.py` â†’ ë¼ë²¨ ë§¤í•‘

- **AI ì„œë¹„ìŠ¤ (`air_travel_back/app/ai_services/`)**
  - `detection_service.py` â†’ YOLO ê¸°ë°˜ ê°ì²´ íƒì§€
  - `rag_service.py` â†’ RAG (Retrieval-Augmented Generation)
  - `tts_service.py` â†’ Azure Speech TTS

- **API ì—”ë“œí¬ì¸íŠ¸**
  - `app/api/v1/endpoints/ai_analysis.py` â†’ AI ë¶„ì„ API

- **ì„¤ì •**
  - `app/core/config.py` â†’ AI ëª¨ë¸ ê²½ë¡œ ì„¤ì •
  - `app/api/v1/api.py` â†’ AI ë¶„ì„ ë¼ìš°í„° ë“±ë¡

---

### 2. í”„ë¡ íŠ¸ì—”ë“œ (React Native + Expo)

- **AI ì¹´ë©”ë¼ í™”ë©´**
  - `frontend/app/ai-camera/index.tsx` â†’ ì¹´ë©”ë¼ ê¸°ë°˜ AI ë¶„ì„ ë©”ì¸ í™”ë©´

- **í™ˆ í™”ë©´ ìˆ˜ì •**
  - `frontend/app/(tabs)/index.tsx` â†’ AR ì•„ì´ì½˜ ë²„íŠ¼ ì¶”ê°€

- **ì„¤ì •**
  - `frontend/app.config.js` â†’ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

---

## ğŸ“¦ ì˜ì¡´ì„± íŒ¨í‚¤ì§€

### ë°±ì—”ë“œ
- `torch` â†’ PyTorch (CLIP ì‹¤í–‰)
- `clip-by-openai` â†’ OpenAI CLIP ëª¨ë¸
- `faiss-cpu` â†’ FAISS ë²¡í„° ê²€ìƒ‰
- `azure-cognitiveservices-speech` â†’ Azure Speech TTS

### í”„ë¡ íŠ¸ì—”ë“œ
- `expo-camera` â†’ ì¹´ë©”ë¼ ê¸°ëŠ¥
- `expo-location` â†’ GPS ìœ„ì¹˜
- `expo-speech` â†’ TTS ìŒì„± ì¶œë ¥

---

## ğŸ”‘ í™˜ê²½ ë³€ìˆ˜ (.env)

```env
AZURE_OPENAI_API_KEY=   # Azure OpenAI API í‚¤
AZURE_SEARCH_ENDPOINT=  # Azure Search ì—”ë“œí¬ì¸íŠ¸
AZURE_SPEECH_KEY=       # Azure Speech í‚¤
FAISS_INDEX_PATH=       # FAISS ì¸ë±ìŠ¤ ê²½ë¡œ (ì˜ˆ: ./ai_data/index.faiss)
META_DATA_PATH=         # ë©”íƒ€ë°ì´í„° ê²½ë¡œ (ì˜ˆ: ./ai_data/meta_baked.json)
